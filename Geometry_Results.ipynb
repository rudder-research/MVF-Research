{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hnr9R6rCG_gHvV3H_XOuK0mt2F-b0RBl",
      "authorship_tag": "ABX9TyPecQ+t284V/PUE0Ct7liRL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudder-research/VCF-RESEARCH/blob/main/Geometry_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUKaSXRNBtXq",
        "outputId": "deca985a-df35-42a0-b417-66b0c3fd1818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/VCF_Research\""
      ],
      "metadata": {
        "id": "4IXIgIFzB6YJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF_Research\"\n",
        "\n",
        "# See what's actually there\n",
        "for root, dirs, files in os.walk(BASE_DIR):\n",
        "    level = root.replace(BASE_DIR, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:10]:  # first 10 files per folder\n",
        "        print(f'{subindent}{file}')"
      ],
      "metadata": {
        "id": "vcJcBjsoCAq0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-Research\"\n",
        "\n",
        "# Check structure\n",
        "if os.path.exists(BASE_DIR):\n",
        "    print(\"âœ“ VCF_Research found\\n\")\n",
        "    for item in os.listdir(BASE_DIR):\n",
        "        path = os.path.join(BASE_DIR, item)\n",
        "        if os.path.isdir(path):\n",
        "            print(f\"ğŸ“ {item}/\")\n",
        "            # Show files in each folder\n",
        "            for file in os.listdir(path)[:5]:\n",
        "                print(f\"   - {file}\")\n",
        "        else:\n",
        "            print(f\"ğŸ“„ {item}\")\n",
        "else:\n",
        "    print(f\"âœ— Not found: {BASE_DIR}\")\n",
        "    print(\"\\nWhat IS in MyDrive:\")\n",
        "    for item in os.listdir(\"/content/drive/MyDrive\")[:10]:\n",
        "        print(f\"  - {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76LQfWBKCGVi",
        "outputId": "b992e43b-ad17-493d-ea98-633e14150bc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ— Not found: /content/drive/MyDrive/VCF-Research\n",
            "\n",
            "What IS in MyDrive:\n",
            "  - Colab Notebooks\n",
            "  - .ssh\n",
            "  - .git\n",
            "  - List of regencies..gdoc\n",
            "  - JasonDrive\n",
            "  - drive_mirror_clone\n",
            "  - VFC Process Flow.gsheet\n",
            "  - Untitled spreadsheet.gsheet\n",
            "  - COMMANDS.ipynb\n",
            "  - Tokens.gdoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\""
      ],
      "metadata": {
        "id": "DjoTEozECPx6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "\n",
        "if os.path.exists(BASE_DIR):\n",
        "    print(\"âœ“ VCF_Research found\\n\")\n",
        "    for item in sorted(os.listdir(BASE_DIR)):\n",
        "        path = os.path.join(BASE_DIR, item)\n",
        "        if os.path.isdir(path):\n",
        "            print(f\"ğŸ“ {item}/\")\n",
        "            files = os.listdir(path)\n",
        "            for file in sorted(files)[:5]:\n",
        "                print(f\"   - {file}\")\n",
        "            if len(files) > 5:\n",
        "                print(f\"   ... and {len(files)-5} more\")\n",
        "        else:\n",
        "            print(f\"ğŸ“„ {item}\")\n",
        "else:\n",
        "    print(f\"âœ— Still not found: {BASE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJRSXm2kCT-h",
        "outputId": "97591030-42b2-4c64-f616-1fc5409e7209"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ VCF_Research found\n",
            "\n",
            "ğŸ“ .git/\n",
            "   - COMMIT_EDITMSG\n",
            "   - FETCH_HEAD\n",
            "   - HEAD\n",
            "   - ORIG_HEAD\n",
            "   - branches\n",
            "   ... and 9 more\n",
            "ğŸ“ Claude11242025/\n",
            "   - 2files.zip\n",
            "   - Claude GitHub Fixer\n",
            "   - CorrectGitHub\n",
            "   - Correction of Directories.zip\n",
            "   - IMPLEMENTATION_SUMMARY.md\n",
            "   ... and 14 more\n",
            "ğŸ“ Outputs/\n",
            "   - Pilot 001\n",
            "   - Pilot 002\n",
            "ğŸ“ PR Requests/\n",
            "   - CELL_7_FIX.txt\n",
            "   - COLAB_CELLS_SIMPLE.txt\n",
            "   - COMPLETE_FIX_INSTRUCTIONS.txt\n",
            "   - DEPLOYMENT_CHECKLIST (1).md\n",
            "   - DEPLOYMENT_CHECKLIST.md\n",
            "   ... and 34 more\n",
            "ğŸ“„ README.md\n",
            "ğŸ“ Research Report 11-24-2025/\n",
            "   - Research Report 11-24-2024.rtf\n",
            "ğŸ“ Research Reports Log/\n",
            "ğŸ“ VCFMSFT/\n",
            "   - .git\n",
            "   - README.md\n",
            "   - data_clean\n",
            "   - data_raw\n",
            "   - docs\n",
            "   ... and 7 more\n",
            "ğŸ“„ VIX_US.numbers\n",
            "ğŸ“ _backup_20251125_164032/\n",
            "   - vcf\n",
            "   - vcf_engine_and_pilots.py\n",
            "ğŸ“ _backup_before_reorganization/\n",
            "   - claude-files\n",
            "   - geometry\n",
            "   - scripts\n",
            "   - src\n",
            "ğŸ“ archive/\n",
            "   - old_geometry_engine\n",
            "ğŸ“ claude-files/\n",
            "   - .gitignore\n",
            "   - CLAUDE_INDEX.md\n",
            "   - Gemini comments on math.txt\n",
            "   - README.md\n",
            "   - notes\n",
            "   ... and 3 more\n",
            "ğŸ“ data/\n",
            "   - panels\n",
            "   - processed\n",
            "   - raw\n",
            "ğŸ“ data_clean/\n",
            "   - CPI_US_normalized.csv\n",
            "   - DGS10_US_normalized.csv\n",
            "   - GDP_US_normalized.csv\n",
            "   - M2_US_normalized.csv\n",
            "   - PPI_US_normalized.csv\n",
            "   ... and 7 more\n",
            "ğŸ“ data_raw/\n",
            "   - CPI_US.csv\n",
            "   - DGS10_US.csv\n",
            "   - GDP_US.csv\n",
            "   - M2_US.csv\n",
            "   - PPI_US.csv\n",
            "   ... and 5 more\n",
            "ğŸ“ docs/\n",
            "   - 11.21.2025 PR\n",
            "   - GPT_Documentation_Package\n",
            "   - GPT_Documentation_Package.zip\n",
            "   - Global_Zip_Collector.md\n",
            "   - Global_Zip_Collector.pdf\n",
            "   ... and 10 more\n",
            "ğŸ“„ env\n",
            "ğŸ“ geometry/\n",
            "   - geometry_panel.csv\n",
            "ğŸ“ notebooks/\n",
            "   - COMMANDS.ipynb\n",
            "   - VFC_Mathematical_Engine_Claud.ipynb\n",
            "   - Visualization_Suite_Claud.ipynb\n",
            "ğŸ“ outputs/\n",
            "   - exports\n",
            "   - figures\n",
            "   - results\n",
            "ğŸ“ registry/\n",
            "   - metrics.csv\n",
            "ğŸ“„ requirements.txt\n",
            "ğŸ“ scripts/\n",
            "   - build_macro_panel.py\n",
            "   - data_loader.py\n",
            "   - geometry_engine.py\n",
            "   - normalize_metrics.py\n",
            "ğŸ“ src/\n",
            "   - geometry_engine\n",
            "   - vcf\n",
            "ğŸ“ tests/\n",
            "   - test_vcf.py\n",
            "ğŸ“ vcf/\n",
            "   - __init__ (1).py\n",
            "   - __init__.py\n",
            "   - __pycache__\n",
            "   - analysis\n",
            "   - core\n",
            "   ... and 2 more\n",
            "ğŸ“„ vcf_engine_and_pilots.py\n",
            "ğŸ“ visuals/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PANEL_PATH = \"/content/drive/MyDrive/VCF_Research/data_clean/normalized_panel.csv\"\n",
        "print(f\"Panel exists: {os.path.exists(PANEL_PATH)}\")\n",
        "\n",
        "# Show what IS in data_clean\n",
        "data_clean = \"/content/drive/MyDrive/VCF_Research/data_clean\"\n",
        "print(\"\\nFiles in data_clean:\")\n",
        "for f in sorted(os.listdir(data_clean)):\n",
        "    print(f\"  - {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "iE9TjHx-DT0Q",
        "outputId": "d3d13c73-ac10-451a-91a2-b4be1980d371"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panel exists: False\n",
            "\n",
            "Files in data_clean:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/VCF_Research/data_clean'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1690973555.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/VCF_Research/data_clean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFiles in data_clean:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - {f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/VCF_Research/data_clean'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Try both possible paths\n",
        "path1 = \"/content/drive/MyDrive/VCF_Research\"\n",
        "path2 = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "path3 = \"/content/drive/MyDrive/JasonDrive/VCF_Research\"\n",
        "\n",
        "print(\"Checking paths:\")\n",
        "print(f\"  {path1}: {os.path.exists(path1)}\")\n",
        "print(f\"  {path2}: {os.path.exists(path2)}\")\n",
        "print(f\"  {path3}: {os.path.exists(path3)}\")\n",
        "\n",
        "# Find which one is correct\n",
        "for path in [path1, path2, path3]:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"\\nâœ“ Found it: {path}\")\n",
        "        data_clean = os.path.join(path, \"data_clean\")\n",
        "        print(f\"  data_clean exists: {os.path.exists(data_clean)}\")\n",
        "        if os.path.exists(data_clean):\n",
        "            print(f\"  Files in data_clean:\")\n",
        "            for f in sorted(os.listdir(data_clean))[:10]:\n",
        "                print(f\"    - {f}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1K0aXJrE_82",
        "outputId": "43ef6005-60e7-4774-de7a-e1cb053cbc81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checking paths:\n",
            "  /content/drive/MyDrive/VCF_Research: False\n",
            "  /content/drive/MyDrive/VCF-RESEARCH: True\n",
            "  /content/drive/MyDrive/JasonDrive/VCF_Research: False\n",
            "\n",
            "âœ“ Found it: /content/drive/MyDrive/VCF-RESEARCH\n",
            "  data_clean exists: True\n",
            "  Files in data_clean:\n",
            "    - CPI_US_normalized.csv\n",
            "    - DGS10_US_normalized.csv\n",
            "    - GDP_US_normalized.csv\n",
            "    - M2_US_normalized.csv\n",
            "    - PPI_US_normalized.csv\n",
            "    - SPY_monthly_clean.csv\n",
            "    - T10Y2Y_US_normalized.csv\n",
            "    - UNRATE_US_normalized.csv\n",
            "    - VIX_monthly_clean.csv\n",
            "    - geometry_panel.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Correct path\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "REGISTRY_PATH = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "PANEL_PATH = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"geometry\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"\\nğŸ§® Starting VCF geometry engine (Option C: long + full)...\")\n",
        "\n",
        "# ---------- Load data ----------\n",
        "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
        "panel = panel.set_index(\"date\").sort_index()\n",
        "\n",
        "with open(REGISTRY_PATH, \"r\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "print(f\"âœ” Loaded normalized panel with {panel.shape[0]} rows and {panel.shape[1]} metrics\")\n",
        "print(f\"âœ” Registry metrics: {len(registry)}\")\n",
        "\n",
        "# ---------- Helper: group metrics by category ----------\n",
        "def metric_ids_for(categories):\n",
        "    return [\n",
        "        metric_id\n",
        "        for metric_id, info in registry.items()\n",
        "        if info.get(\"category\") in categories and metric_id in panel.columns\n",
        "    ]\n",
        "\n",
        "macro_like_cats = {\"Macro\", \"Labor\", \"Rates\"}\n",
        "liquidity_cats = {\"Liquidity\", \"Rates\"}\n",
        "risk_cats = {\"Volatility\"}\n",
        "equity_cats = {\"Equities\"}\n",
        "\n",
        "macro_metrics = metric_ids_for(macro_like_cats)\n",
        "liquidity_metrics = metric_ids_for(liquidity_cats)\n",
        "risk_metrics = metric_ids_for(risk_cats)\n",
        "equity_metrics = metric_ids_for(equity_cats)\n",
        "\n",
        "print(\"\\nğŸ“Œ Metric groups used:\")\n",
        "print(\"  Macro-like     :\", macro_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1c2m1JtPMQ27",
        "outputId": "ad3de228-e019-4537-c1a7-df3e2d3e7c6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-3431875502.py, line 45)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3431875502.py\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    print(\"  Macro-like     :\", macro_metrics\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Correct path\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "REGISTRY_PATH = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "PANEL_PATH = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"geometry\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"\\nğŸ§® Starting VCF geometry engine (Option C: long + full)...\")\n",
        "\n",
        "# ---------- Load data ----------\n",
        "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
        "panel = panel.set_index(\"date\").sort_index()\n",
        "\n",
        "with open(REGISTRY_PATH, \"r\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "print(f\"âœ” Loaded normalized panel with {panel.shape[0]} rows and {panel.shape[1]} metrics\")\n",
        "print(f\"âœ” Registry metrics: {len(registry)}\")\n",
        "\n",
        "# ---------- Helper: group metrics by category ----------\n",
        "def metric_ids_for(categories):\n",
        "    return [\n",
        "        metric_id\n",
        "        for metric_id, info in registry.items()\n",
        "        if info.get(\"category\") in categories and metric_id in panel.columns\n",
        "    ]\n",
        "\n",
        "macro_like_cats = {\"Macro\", \"Labor\", \"Rates\"}\n",
        "liquidity_cats = {\"Liquidity\", \"Rates\"}\n",
        "risk_cats = {\"Volatility\"}\n",
        "equity_cats = {\"Equities\"}\n",
        "\n",
        "macro_metrics = metric_ids_for(macro_like_cats)\n",
        "liquidity_metrics = metric_ids_for(liquidity_cats)\n",
        "risk_metrics = metric_ids_for(risk_cats)\n",
        "equity_metrics = metric_ids_for(equity_cats)\n",
        "\n",
        "print(\"\\nğŸ“Œ Metric groups used:\")\n",
        "print(\"  Macro-like     :\", macro_metrics)\n",
        "print(\"  Liquidity-like :\", liquidity_metrics)\n",
        "print(\"  Risk (vol)     :\", risk_metrics)\n",
        "print(\"  Equity         :\", equity_metrics)\n",
        "\n",
        "# Build pillar scores\n",
        "scores = pd.DataFrame(index=panel.index)\n",
        "scores[\"macro_score\"] = panel[macro_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"liquidity_score\"] = panel[liquidity_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"risk_score\"] = panel[risk_metrics].mean(axis=1, skipna=True) if risk_metrics else np.nan\n",
        "scores[\"equity_score\"] = panel[equity_metrics].mean(axis=1, skipna=True) if equity_metrics else np.nan\n",
        "\n",
        "# Z-score helper\n",
        "def zscore(series: pd.Series) -> pd.Series:\n",
        "    s = series.dropna()\n",
        "    if s.empty or s.std(ddof=0) == 0:\n",
        "        return series * np.nan\n",
        "    z = (series - s.mean()) / s.std(ddof=0)\n",
        "    return z\n",
        "\n",
        "# Long macro-only geometry\n",
        "macro_z = zscore(scores[\"macro_score\"])\n",
        "liq_z = zscore(scores[\"liquidity_score\"])\n",
        "theta_long = np.degrees(np.arctan2(macro_z, liq_z))\n",
        "coherence_long = np.sqrt(macro_z**2 + liq_z**2)\n",
        "\n",
        "geo_long = pd.DataFrame({\n",
        "    \"macro_score\": scores[\"macro_score\"],\n",
        "    \"liquidity_score\": scores[\"liquidity_score\"],\n",
        "    \"theta_macro_deg\": theta_long,\n",
        "    \"coherence_macro\": coherence_long,\n",
        "}, index=scores.index)\n",
        "\n",
        "long_path = os.path.join(OUT_DIR, \"vcf_geometry_long_macro.csv\")\n",
        "geo_long.to_csv(long_path, index_label=\"date\")\n",
        "print(f\"\\nğŸ“œ Long macro geometry saved: {long_path}\")\n",
        "print(f\"   Rows: {geo_long.shape[0]} (theta valid from: {geo_long['theta_macro_deg'].first_valid_index()})\")\n",
        "\n",
        "# Full 4-pillar geometry\n",
        "mask_full = scores[\"risk_score\"].notna() & scores[\"equity_score\"].notna()\n",
        "\n",
        "if mask_full.sum() == 0:\n",
        "    print(\"\\nâš  No overlapping dates with risk + equity. Full geometry not computed.\")\n",
        "else:\n",
        "    macro_z_f = zscore(scores.loc[mask_full, \"macro_score\"])\n",
        "    liq_z_f = zscore(scores.loc[mask_full, \"liquidity_score\"])\n",
        "    risk_z = zscore(scores.loc[mask_full, \"risk_score\"])\n",
        "    equity_z = zscore(scores.loc[mask_full, \"equity_score\"])\n",
        "\n",
        "    theta_full = np.degrees(np.arctan2(macro_z_f, liq_z_f))\n",
        "    phi_full = np.degrees(np.arctan2(equity_z, risk_z))\n",
        "\n",
        "    coherence_theta = np.sqrt(macro_z_f**2 + liq_z_f**2)\n",
        "    coherence_phi = np.sqrt(equity_z**2 + risk_z**2)\n",
        "\n",
        "    geo_full = pd.DataFrame({\n",
        "        \"macro_score\": scores.loc[mask_full, \"macro_score\"],\n",
        "        \"liquidity_score\": scores.loc[mask_full, \"liquidity_score\"],\n",
        "        \"risk_score\": scores.loc[mask_full, \"risk_score\"],\n",
        "        \"equity_score\": scores.loc[mask_full, \"equity_score\"],\n",
        "        \"theta_deg\": theta_full,\n",
        "        \"phi_deg\": phi_full,\n",
        "        \"coherence_theta\": coherence_theta,\n",
        "        \"coherence_phi\": coherence_phi,\n",
        "    }, index=scores.index[mask_full])\n",
        "\n",
        "    full_path = os.path.join(OUT_DIR, \"vcf_geometry_full.csv\")\n",
        "    geo_full.to_csv(full_path, index_label=\"date\")\n",
        "    print(f\"\\nğŸ“œ Full geometry saved: {full_path}\")\n",
        "    print(f\"   Rows: {geo_full.shape[0]} (first: {geo_full.index.min()}, last: {geo_full.index.max()})\")\n",
        "\n",
        "print(\"\\nâœ… VCF geometry engine COMPLETE.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvr1FSYlMops",
        "outputId": "78b8c0b9-8a7a-4719-adec-09414ee8ce27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§® Starting VCF geometry engine (Option C: long + full)...\n",
            "âœ” Loaded normalized panel with 16947 rows and 9 metrics\n",
            "âœ” Registry metrics: 31\n",
            "\n",
            "ğŸ“Œ Metric groups used:\n",
            "  Macro-like     : ['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US', 'DGS10_US', 'T10Y2Y_US']\n",
            "  Liquidity-like : ['M2_US', 'DGS10_US', 'T10Y2Y_US']\n",
            "  Risk (vol)     : ['VIX_US']\n",
            "  Equity         : ['SPY_US']\n",
            "\n",
            "ğŸ“œ Long macro geometry saved: /content/drive/MyDrive/VCF-RESEARCH/geometry/vcf_geometry_long_macro.csv\n",
            "   Rows: 16947 (theta valid from: 1962-01-02 00:00:00)\n",
            "\n",
            "ğŸ“œ Full geometry saved: /content/drive/MyDrive/VCF-RESEARCH/geometry/vcf_geometry_full.csv\n",
            "   Rows: 394 (first: 1993-02-28 00:00:00, last: 2025-11-30 00:00:00)\n",
            "\n",
            "âœ… VCF geometry engine COMPLETE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "full_path = os.path.join(BASE_DIR, \"geometry\", \"vcf_geometry_full.csv\")\n",
        "\n",
        "geo_full = pd.read_csv(full_path, parse_dates=['date'])\n",
        "geo_full = geo_full.set_index('date').sort_index()\n",
        "\n",
        "print(\"ğŸ“Š Latest VCF Geometry (last 10 observations):\\n\")\n",
        "print(geo_full.tail(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ˆ Current Market State (most recent):\\n\")\n",
        "latest = geo_full.iloc[-1]\n",
        "print(f\"Date: {geo_full.index[-1].strftime('%Y-%m-%d')}\")\n",
        "print(f\"\\nPillar Scores:\")\n",
        "print(f\"  Macro:     {latest['macro_score']:>7.3f}\")\n",
        "print(f\"  Liquidity: {latest['liquidity_score']:>7.3f}\")\n",
        "print(f\"  Risk:      {latest['risk_score']:>7.3f}\")\n",
        "print(f\"  Equity:    {latest['equity_score']:>7.3f}\")\n",
        "\n",
        "print(f\"\\nGeometric State:\")\n",
        "print(f\"  Theta (Macro/Liq):  {latest['theta_deg']:>7.1f}Â°\")\n",
        "print(f\"  Phi (Equity/Risk):  {latest['phi_deg']:>7.1f}Â°\")\n",
        "print(f\"  Coherence Theta:    {latest['coherence_theta']:>7.3f}\")\n",
        "print(f\"  Coherence Phi:      {latest['coherence_phi']:>7.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ” Interpretation:\\n\")\n",
        "\n",
        "# Theta interpretation (Macro/Liquidity plane)\n",
        "theta = latest['theta_deg']\n",
        "if theta > 45 and theta < 135:\n",
        "    print(\"  Theta: MACRO DOMINANT (strong macro, weak liquidity)\")\n",
        "elif theta > -135 and theta < -45:\n",
        "    print(\"  Theta: BOTH WEAK (macro and liquidity below average)\")\n",
        "elif theta > -45 and theta < 45:\n",
        "    print(\"  Theta: LIQUIDITY DOMINANT (strong liquidity, weak macro)\")\n",
        "else:\n",
        "    print(\"  Theta: BOTH STRONG (macro and liquidity above average)\")\n",
        "\n",
        "# Phi interpretation (Equity/Risk plane)\n",
        "phi = latest['phi_deg']\n",
        "if phi > 45 and phi < 135:\n",
        "    print(\"  Phi: RISK-ON (equities strong, volatility low)\")\n",
        "elif phi > -135 and phi < -45:\n",
        "    print(\"  Phi: RISK-OFF (equities weak, volatility high)\")\n",
        "elif phi > -45 and phi < 45:\n",
        "    print(\"  Phi: LOW VOL GRIND (low vol, mixed equities)\")\n",
        "else:\n",
        "    print(\"  Phi: HIGH VOL RALLY (high vol, strong equities)\")\n",
        "\n",
        "# Coherence interpretation\n",
        "if latest['coherence_theta'] > 1.0:\n",
        "    print(f\"  Strong macro/liquidity signal (coherence: {latest['coherence_theta']:.2f})\")\n",
        "else:\n",
        "    print(f\"  Weak macro/liquidity signal (coherence: {latest['coherence_theta']:.2f})\")\n",
        "\n",
        "if latest['coherence_phi'] > 1.0:\n",
        "    print(f\"  Strong equity/risk signal (coherence: {latest['coherence_phi']:.2f})\")\n",
        "else:\n",
        "    print(f\"  Weak equity/risk signal (coherence: {latest['coherence_phi']:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygJEHHprNknm",
        "outputId": "b25af729-e53e-4e2a-c5b7-12e459aa5ecf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Latest VCF Geometry (last 10 observations):\n",
            "\n",
            "            macro_score  liquidity_score  risk_score  equity_score  theta_deg  \\\n",
            "date                                                                            \n",
            "2025-02-28     0.057737         0.057737    0.014569      2.851701       45.0   \n",
            "2025-03-31     0.007068         0.007068    0.371812      2.631025       45.0   \n",
            "2025-04-30    -0.128272        -0.128272    0.698048      2.598600       45.0   \n",
            "2025-05-31          NaN              NaN   -0.128328      2.831592        NaN   \n",
            "2025-06-30    -0.089174        -0.089174   -0.376375      3.034074       45.0   \n",
            "2025-07-31    -0.018117        -0.018117   -0.377723      3.129491       45.0   \n",
            "2025-08-31          NaN              NaN   -0.561063      3.216459        NaN   \n",
            "2025-09-30    -0.124530        -0.124530   -0.437039      3.370526       45.0   \n",
            "2025-10-31    -0.105819        -0.105819   -0.280661      3.477302       45.0   \n",
            "2025-11-30          NaN              NaN    0.592897      3.329511        NaN   \n",
            "\n",
            "              phi_deg  coherence_theta  coherence_phi  \n",
            "date                                                   \n",
            "2025-02-28  90.000672         0.979512       2.855327  \n",
            "2025-03-31  82.461619         0.866377       2.657337  \n",
            "2025-04-30  75.621664         0.564187       2.686039  \n",
            "2025-05-31  92.816722              NaN       2.838622  \n",
            "2025-06-30  97.159066         0.651487       3.061802  \n",
            "2025-07-31  96.966658         0.810144       3.156777  \n",
            "2025-08-31  99.895599              NaN       3.269186  \n",
            "2025-09-30  97.441206         0.572543       3.403475  \n",
            "2025-10-31  94.731274         0.614321       3.493628  \n",
            "2025-11-30  80.391234              NaN       3.381180  \n",
            "\n",
            "======================================================================\n",
            "ğŸ“ˆ Current Market State (most recent):\n",
            "\n",
            "Date: 2025-11-30\n",
            "\n",
            "Pillar Scores:\n",
            "  Macro:         nan\n",
            "  Liquidity:     nan\n",
            "  Risk:        0.593\n",
            "  Equity:      3.330\n",
            "\n",
            "Geometric State:\n",
            "  Theta (Macro/Liq):      nanÂ°\n",
            "  Phi (Equity/Risk):     80.4Â°\n",
            "  Coherence Theta:        nan\n",
            "  Coherence Phi:        3.381\n",
            "\n",
            "======================================================================\n",
            "ğŸ” Interpretation:\n",
            "\n",
            "  Theta: BOTH STRONG (macro and liquidity above average)\n",
            "  Phi: RISK-ON (equities strong, volatility low)\n",
            "  Weak macro/liquidity signal (coherence: nan)\n",
            "  Strong equity/risk signal (coherence: 3.38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "registry_path = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "\n",
        "with open(registry_path, 'r') as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "# Move rates from \"Rates\" to \"Liquidity\" category\n",
        "# (Rates typically reflect monetary policy and liquidity conditions)\n",
        "rates_metrics = ['DGS2_US', 'DGS10_US', 'DGS30_US', 'T10Y2Y_US']\n",
        "\n",
        "for metric_id in rates_metrics:\n",
        "    if metric_id in registry:\n",
        "        old_cat = registry[metric_id]['category']\n",
        "        registry[metric_id]['category'] = 'Liquidity'\n",
        "        print(f\"âœ“ Moved {metric_id}: {old_cat} â†’ Liquidity\")\n",
        "\n",
        "# Save updated registry\n",
        "with open(registry_path, 'w') as f:\n",
        "    json.dump(registry, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… Registry updated. Rates now in Liquidity category only.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJPjXaKgORiP",
        "outputId": "8bb2d6e6-cc1c-4c32-ff4a-047f15c54671"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Moved DGS2_US: Rates â†’ Liquidity\n",
            "âœ“ Moved DGS10_US: Rates â†’ Liquidity\n",
            "âœ“ Moved DGS30_US: Rates â†’ Liquidity\n",
            "âœ“ Moved T10Y2Y_US: Rates â†’ Liquidity\n",
            "\n",
            "âœ… Registry updated. Rates now in Liquidity category only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "âœ“ Moved DGS2_US: Rates â†’ Liquidity\n",
        "âœ“ Moved DGS10_US: Rates â†’ Liquidity\n",
        "âœ“ Moved DGS30_US: Rates â†’ Liquidity\n",
        "âœ“ Moved T10Y2Y_US: Rates â†’ Liquidity\n",
        "\n",
        "âœ… Registry updated. Rates now in Liquidity category only.\n"
      ],
      "metadata": {
        "id": "2Lb37i0wOhwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "REGISTRY_PATH = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "PANEL_PATH = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"geometry\")\n",
        "\n",
        "print(\"\\nğŸ§® Re-running VCF geometry engine with corrected categories...\")\n",
        "\n",
        "# Load data\n",
        "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
        "panel = panel.set_index(\"date\").sort_index()\n",
        "\n",
        "with open(REGISTRY_PATH, \"r\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "# Group metrics by category\n",
        "def metric_ids_for(categories):\n",
        "    return [\n",
        "        metric_id\n",
        "        for metric_id, info in registry.items()\n",
        "        if info.get(\"category\") in categories and metric_id in panel.columns\n",
        "    ]\n",
        "\n",
        "macro_metrics = metric_ids_for({\"Macro\", \"Labor\"})\n",
        "liquidity_metrics = metric_ids_for({\"Liquidity\"})\n",
        "risk_metrics = metric_ids_for({\"Volatility\"})\n",
        "equity_metrics = metric_ids_for({\"Equities\"})\n",
        "\n",
        "print(\"\\nğŸ“Œ Corrected metric groups:\")\n",
        "print(\"  Macro     :\", macro_metrics)\n",
        "print(\"  Liquidity :\", liquidity_metrics)\n",
        "print(\"  Risk      :\", risk_metrics)\n",
        "print(\"  Equity    :\", equity_metrics)\n",
        "\n",
        "# Build pillar scores\n",
        "scores = pd.DataFrame(index=panel.index)\n",
        "scores[\"macro_score\"] = panel[macro_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"liquidity_score\"] = panel[liquidity_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"risk_score\"] = panel[risk_metrics].mean(axis=1, skipna=True) if risk_metrics else np.nan\n",
        "scores[\"equity_score\"] = panel[equity_metrics].mean(axis=1, skipna=True) if equity_metrics else np.nan\n",
        "\n",
        "def zscore(series: pd.Series) -> pd.Series:\n",
        "    s = series.dropna()\n",
        "    if s.empty or s.std(ddof=0) == 0:\n",
        "        return series * np.nan\n",
        "    z = (series - s.mean()) / s.std(ddof=0)\n",
        "    return z\n",
        "\n",
        "# Long macro geometry\n",
        "macro_z = zscore(scores[\"macro_score\"])\n",
        "liq_z = zscore(scores[\"liquidity_score\"])\n",
        "theta_long = np.degrees(np.arctan2(macro_z, liq_z))\n",
        "coherence_long = np.sqrt(macro_z**2 + liq_z**2)\n",
        "\n",
        "geo_long = pd.DataFrame({\n",
        "    \"macro_score\": scores[\"macro_score\"],\n",
        "    \"liquidity_score\": scores[\"liquidity_score\"],\n",
        "    \"theta_macro_deg\": theta_long,\n",
        "    \"coherence_macro\": coherence_long,\n",
        "}, index=scores.index)\n",
        "\n",
        "long_path = os.path.join(OUT_DIR, \"vcf_geometry_long_macro.csv\")\n",
        "geo_long.to_csv(long_path, index_label=\"date\")\n",
        "print(f\"\\nğŸ“œ Long macro geometry saved\")\n",
        "\n",
        "# Full 4-pillar geometry\n",
        "mask_full = scores[\"risk_score\"].notna() & scores[\"equity_score\"].notna()\n",
        "\n",
        "if mask_full.sum() > 0:\n",
        "    macro_z_f = zscore(scores.loc[mask_full, \"macro_score\"])\n",
        "    liq_z_f = zscore(scores.loc[mask_full, \"liquidity_score\"])\n",
        "    risk_z = zscore(scores.loc[mask_full, \"risk_score\"])\n",
        "    equity_z = zscore(scores.loc[mask_full, \"equity_score\"])\n",
        "\n",
        "    theta_full = np.degrees(np.arctan2(macro_z_f, liq_z_f))\n",
        "    phi_full = np.degrees(np.arctan2(equity_z, risk_z))\n",
        "\n",
        "    coherence_theta = np.sqrt(macro_z_f**2 + liq_z_f**2)\n",
        "    coherence_phi = np.sqrt(equity_z**2 + risk_z**2)\n",
        "\n",
        "    geo_full = pd.DataFrame({\n",
        "        \"macro_score\": scores.loc[mask_full, \"macro_score\"],\n",
        "        \"liquidity_score\": scores.loc[mask_full, \"liquidity_score\"],\n",
        "        \"risk_score\": scores.loc[mask_full, \"risk_score\"],\n",
        "        \"equity_score\": scores.loc[mask_full, \"equity_score\"],\n",
        "        \"theta_deg\": theta_full,\n",
        "        \"phi_deg\": phi_full,\n",
        "        \"coherence_theta\": coherence_theta,\n",
        "        \"coherence_phi\": coherence_phi,\n",
        "    }, index=scores.index[mask_full])\n",
        "\n",
        "    full_path = os.path.join(OUT_DIR, \"vcf_geometry_full.csv\")\n",
        "    geo_full.to_csv(full_path, index_label=\"date\")\n",
        "    print(f\"ğŸ“œ Full geometry saved: {geo_full.shape[0]} rows\")\n",
        "\n",
        "    # Show latest values\n",
        "    print(\"\\nğŸ“Š Latest 5 observations:\")\n",
        "    print(geo_full[['theta_deg', 'phi_deg', 'coherence_theta', 'coherence_phi']].tail())\n",
        "\n",
        "print(\"\\nâœ… VCF geometry engine COMPLETE.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90lloNTgOmKy",
        "outputId": "6129bd13-fc6e-456f-edbc-b966b8974153"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§® Re-running VCF geometry engine with corrected categories...\n",
            "\n",
            "ğŸ“Œ Corrected metric groups:\n",
            "  Macro     : ['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US']\n",
            "  Liquidity : ['M2_US', 'DGS10_US', 'T10Y2Y_US']\n",
            "  Risk      : ['VIX_US']\n",
            "  Equity    : ['SPY_US']\n",
            "\n",
            "ğŸ“œ Long macro geometry saved\n",
            "ğŸ“œ Full geometry saved: 394 rows\n",
            "\n",
            "ğŸ“Š Latest 5 observations:\n",
            "            theta_deg    phi_deg  coherence_theta  coherence_phi\n",
            "date                                                            \n",
            "2025-07-31        NaN  96.966658              NaN       3.156777\n",
            "2025-08-31        NaN  99.895599              NaN       3.269186\n",
            "2025-09-30        NaN  97.441206              NaN       3.403475\n",
            "2025-10-31        NaN  94.731274              NaN       3.493628\n",
            "2025-11-30        NaN  80.391234              NaN       3.381180\n",
            "\n",
            "âœ… VCF geometry engine COMPLETE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "full_path = os.path.join(BASE_DIR, \"geometry\", \"vcf_geometry_full.csv\")\n",
        "\n",
        "geo_full = pd.read_csv(full_path, parse_dates=['date'])\n",
        "geo_full = geo_full.set_index('date').sort_index()\n",
        "\n",
        "# Find rows where theta is NOT NaN\n",
        "valid_theta = geo_full[geo_full['theta_deg'].notna()]\n",
        "\n",
        "print(\"ğŸ“Š Most recent observations WITH valid theta:\\n\")\n",
        "print(valid_theta.tail(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ˆ Latest COMPLETE Market State:\\n\")\n",
        "latest = valid_theta.iloc[-1]\n",
        "print(f\"Date: {valid_theta.index[-1].strftime('%Y-%m-%d')}\")\n",
        "print(f\"\\nPillar Scores:\")\n",
        "print(f\"  Macro:     {latest['macro_score']:>7.3f}\")\n",
        "print(f\"  Liquidity: {latest['liquidity_score']:>7.3f}\")\n",
        "print(f\"  Risk:      {latest['risk_score']:>7.3f}\")\n",
        "print(f\"  Equity:    {latest['equity_score']:>7.3f}\")\n",
        "\n",
        "print(f\"\\nGeometric State:\")\n",
        "print(f\"  Theta (Macro/Liq):  {latest['theta_deg']:>7.1f}Â°\")\n",
        "print(f\"  Phi (Equity/Risk):  {latest['phi_deg']:>7.1f}Â°\")\n",
        "print(f\"  Coherence Theta:    {latest['coherence_theta']:>7.3f}\")\n",
        "print(f\"  Coherence Phi:      {latest['coherence_phi']:>7.3f}\")\n",
        "\n",
        "# Check how theta varies over time\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“‰ Theta variation over last year (to verify it's not stuck):\\n\")\n",
        "last_year = valid_theta.last('12M')[['theta_deg', 'coherence_theta']]\n",
        "print(last_year.describe())\n",
        "print(f\"\\nTheta range: {last_year['theta_deg'].min():.1f}Â° to {last_year['theta_deg'].max():.1f}Â°\")\n",
        "print(f\"Theta std dev: {last_year['theta_deg'].std():.1f}Â°\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "ZMkQdX7sOyWu",
        "outputId": "7ce66340-bc86-412f-f98e-c4c317548a76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Most recent observations WITH valid theta:\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [macro_score, liquidity_score, risk_score, equity_score, theta_deg, phi_deg, coherence_theta, coherence_phi]\n",
            "Index: []\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ˆ Latest COMPLETE Market State:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1817016162.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸ“ˆ Latest COMPLETE Market State:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_theta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Date: {valid_theta.index[-1].strftime('%Y-%m-%d')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nPillar Scores:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "panel_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "\n",
        "panel = pd.read_csv(panel_path, parse_dates=['date'])\n",
        "panel = panel.set_index('date').sort_index()\n",
        "\n",
        "# Check macro metrics\n",
        "macro_cols = ['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US']\n",
        "liquidity_cols = ['M2_US', 'DGS10_US', 'T10Y2Y_US']\n",
        "\n",
        "print(\"Macro metrics data availability:\")\n",
        "for col in macro_cols:\n",
        "    valid = panel[col].notna().sum()\n",
        "    first = panel[col].first_valid_index()\n",
        "    last = panel[col].last_valid_index()\n",
        "    print(f\"  {col}: {valid} valid rows ({first} to {last})\")\n",
        "\n",
        "print(\"\\nLiquidity metrics data availability:\")\n",
        "for col in liquidity_cols:\n",
        "    valid = panel[col].notna().sum()\n",
        "    first = panel[col].first_valid_index()\n",
        "    last = panel[col].last_valid_index()\n",
        "    print(f\"  {col}: {valid} valid rows ({first} to {last})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Checking sample dates for overlap:\\n\")\n",
        "\n",
        "# Check a few sample dates\n",
        "sample_dates = ['1993-03-31', '2000-01-31', '2020-01-31', '2024-12-31']\n",
        "for date_str in sample_dates:\n",
        "    if date_str in panel.index:\n",
        "        row = panel.loc[date_str]\n",
        "        macro_vals = row[macro_cols].notna().sum()\n",
        "        liq_vals = row[liquidity_cols].notna().sum()\n",
        "        print(f\"{date_str}: {macro_vals}/4 macro, {liq_vals}/3 liquidity\")"
      ],
      "metadata": {
        "id": "QvEI5gFCO7kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "panel_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "\n",
        "panel = pd.read_csv(panel_path, parse_dates=['date'])\n",
        "panel = panel.set_index('date').sort_index()\n",
        "\n",
        "# Check macro metrics\n",
        "macro_cols = ['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US']\n",
        "liquidity_cols = ['M2_US', 'DGS10_US', 'T10Y2Y_US']\n",
        "\n",
        "print(\"Macro metrics data availability:\")\n",
        "for col in macro_cols:\n",
        "    valid = panel[col].notna().sum()\n",
        "    first = panel[col].first_valid_index()\n",
        "    last = panel[col].last_valid_index()\n",
        "    print(f\"  {col}: {valid} valid rows ({first} to {last})\")\n",
        "\n",
        "print(\"\\nLiquidity metrics data availability:\")\n",
        "for col in liquidity_cols:\n",
        "    valid = panel[col].notna().sum()\n",
        "    first = panel[col].first_valid_index()\n",
        "    last = panel[col].last_valid_index()\n",
        "    print(f\"  {col}: {valid} valid rows ({first} to {last})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Checking sample dates for overlap:\\n\")\n",
        "\n",
        "# Check a few sample dates\n",
        "sample_dates = ['1993-03-31', '2000-01-31', '2020-01-31', '2024-12-31']\n",
        "for date_str in sample_dates:\n",
        "    if date_str in panel.index:\n",
        "        row = panel.loc[date_str]\n",
        "        macro_vals = row[macro_cols].notna().sum()\n",
        "        liq_vals = row[liquidity_cols].notna().sum()\n",
        "        print(f\"{date_str}: {macro_vals}/4 macro, {liq_vals}/3 liquidity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44LBGNXjO9BC",
        "outputId": "b1b17166-d1a5-4cdb-90b2-7e66917fa24d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro metrics data availability:\n",
            "  GDP_US: 310 valid rows (1948-01-01 00:00:00 to 2025-04-01 00:00:00)\n",
            "  CPI_US: 910 valid rows (1949-12-01 00:00:00 to 2025-09-01 00:00:00)\n",
            "  PPI_US: 1317 valid rows (1915-12-01 00:00:00 to 2025-08-01 00:00:00)\n",
            "  UNRATE_US: 932 valid rows (1948-01-01 00:00:00 to 2025-08-01 00:00:00)\n",
            "\n",
            "Liquidity metrics data availability:\n",
            "  M2_US: 750 valid rows (1963-04-01 00:00:00 to 2025-09-01 00:00:00)\n",
            "  DGS10_US: 15954 valid rows (1962-01-02 00:00:00 to 2025-11-17 00:00:00)\n",
            "  T10Y2Y_US: 12363 valid rows (1976-06-01 00:00:00 to 2025-11-18 00:00:00)\n",
            "\n",
            "======================================================================\n",
            "Checking sample dates for overlap:\n",
            "\n",
            "1993-03-31: 0/4 macro, 2/3 liquidity\n",
            "2000-01-31: 0/4 macro, 2/3 liquidity\n",
            "2020-01-31: 0/4 macro, 2/3 liquidity\n",
            "2024-12-31: 0/4 macro, 2/3 liquidity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "panel_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "output_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel_monthly.csv\")\n",
        "\n",
        "# Load panel\n",
        "panel = pd.read_csv(panel_path, parse_dates=['date'])\n",
        "panel = panel.set_index('date').sort_index()\n",
        "\n",
        "print(f\"Original panel: {panel.shape[0]} rows (mixed daily/monthly)\")\n",
        "\n",
        "# Resample to month-end, taking last observation of each month\n",
        "panel_monthly = panel.resample('ME').last()\n",
        "\n",
        "# Forward fill to handle months where some metrics are missing\n",
        "# (e.g., daily rates data will fill forward to month end)\n",
        "panel_monthly = panel_monthly.fillna(method='ffill', limit=5)\n",
        "\n",
        "print(f\"Monthly panel: {panel_monthly.shape[0]} rows\")\n",
        "\n",
        "# Check sample dates\n",
        "print(\"\\nğŸ“Š Sample monthly data (checking overlap):\\n\")\n",
        "sample_dates = ['2020-01-31', '2020-02-29', '2024-12-31', '2025-09-30']\n",
        "for date_str in sample_dates:\n",
        "    if date_str in panel_monthly.index:\n",
        "        row = panel_monthly.loc[date_str]\n",
        "        macro_vals = row[['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US']].notna().sum()\n",
        "        liq_vals = row[['M2_US', 'DGS10_US', 'T10Y2Y_US']].notna().sum()\n",
        "        print(f\"{date_str}: {macro_vals}/4 macro, {liq_vals}/3 liquidity\")\n",
        "\n",
        "# Save\n",
        "panel_monthly.to_csv(output_path)\n",
        "print(f\"\\nâœ… Saved monthly panel to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1xmuBTUPJXf",
        "outputId": "69758cbc-66c7-4a12-b9e2-099f071f341c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original panel: 16947 rows (mixed daily/monthly)\n",
            "Monthly panel: 1355 rows\n",
            "\n",
            "ğŸ“Š Sample monthly data (checking overlap):\n",
            "\n",
            "2020-01-31: 4/4 macro, 3/3 liquidity\n",
            "2020-02-29: 4/4 macro, 3/3 liquidity\n",
            "2024-12-31: 4/4 macro, 3/3 liquidity\n",
            "2025-09-30: 4/4 macro, 3/3 liquidity\n",
            "\n",
            "âœ… Saved monthly panel to: /content/drive/MyDrive/VCF-RESEARCH/data_clean/normalized_panel_monthly.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2944326976.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  panel_monthly = panel_monthly.fillna(method='ffill', limit=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "REGISTRY_PATH = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "PANEL_PATH = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel_monthly.csv\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"geometry\")\n",
        "\n",
        "print(\"\\nğŸ§® Running VCF geometry engine with MONTHLY panel...\")\n",
        "\n",
        "# Load data\n",
        "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
        "panel = panel.set_index(\"date\").sort_index()\n",
        "\n",
        "with open(REGISTRY_PATH, \"r\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "# Group metrics\n",
        "def metric_ids_for(categories):\n",
        "    return [\n",
        "        metric_id\n",
        "        for metric_id, info in registry.items()\n",
        "        if info.get(\"category\") in categories and metric_id in panel.columns\n",
        "    ]\n",
        "\n",
        "macro_metrics = metric_ids_for({\"Macro\", \"Labor\"})\n",
        "liquidity_metrics = metric_ids_for({\"Liquidity\"})\n",
        "risk_metrics = metric_ids_for({\"Volatility\"})\n",
        "equity_metrics = metric_ids_for({\"Equities\"})\n",
        "\n",
        "print(f\"âœ” Panel: {panel.shape[0]} rows, {panel.shape[1]} metrics\")\n",
        "print(f\"  Macro: {macro_metrics}\")\n",
        "print(f\"  Liquidity: {liquidity_metrics}\")\n",
        "print(f\"  Risk: {risk_metrics}\")\n",
        "print(f\"  Equity: {equity_metrics}\")\n",
        "\n",
        "# Build pillar scores\n",
        "scores = pd.DataFrame(index=panel.index)\n",
        "scores[\"macro_score\"] = panel[macro_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"liquidity_score\"] = panel[liquidity_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"risk_score\"] = panel[risk_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"equity_score\"] = panel[equity_metrics].mean(axis=1, skipna=True)\n",
        "\n",
        "def zscore(series):\n",
        "    s = series.dropna()\n",
        "    if s.empty or s.std(ddof=0) == 0:\n",
        "        return series * np.nan\n",
        "    return (series - s.mean()) / s.std(ddof=0)\n",
        "\n",
        "# Full 4-pillar geometry\n",
        "mask_full = (scores[\"macro_score\"].notna() & scores[\"liquidity_score\"].notna() &\n",
        "             scores[\"risk_score\"].notna() & scores[\"equity_score\"].notna())\n",
        "\n",
        "print(f\"\\nâœ” Full geometry rows: {mask_full.sum()}\")\n",
        "\n",
        "macro_z = zscore(scores.loc[mask_full, \"macro_score\"])\n",
        "liq_z = zscore(scores.loc[mask_full, \"liquidity_score\"])\n",
        "risk_z = zscore(scores.loc[mask_full, \"risk_score\"])\n",
        "equity_z = zscore(scores.loc[mask_full, \"equity_score\"])\n",
        "\n",
        "theta = np.degrees(np.arctan2(macro_z, liq_z))\n",
        "phi = np.degrees(np.arctan2(equity_z, risk_z))\n",
        "coherence_theta = np.sqrt(macro_z**2 + liq_z**2)\n",
        "coherence_phi = np.sqrt(equity_z**2 + risk_z**2)\n",
        "\n",
        "geo_full = pd.DataFrame({\n",
        "    \"macro_score\": scores.loc[mask_full, \"macro_score\"],\n",
        "    \"liquidity_score\": scores.loc[mask_full, \"liquidity_score\"],\n",
        "    \"risk_score\": scores.loc[mask_full, \"risk_score\"],\n",
        "    \"equity_score\": scores.loc[mask_full, \"equity_score\"],\n",
        "    \"theta_deg\": theta,\n",
        "    \"phi_deg\": phi,\n",
        "    \"coherence_theta\": coherence_theta,\n",
        "    \"coherence_phi\": coherence_phi,\n",
        "}, index=scores.index[mask_full])\n",
        "\n",
        "full_path = os.path.join(OUT_DIR, \"vcf_geometry_full.csv\")\n",
        "geo_full.to_csv(full_path, index_label=\"date\")\n",
        "\n",
        "print(f\"\\nğŸ“œ Full geometry saved: {full_path}\")\n",
        "print(f\"   Date range: {geo_full.index.min()} to {geo_full.index.max()}\")\n",
        "print(f\"\\nğŸ“Š Latest 10 observations:\\n\")\n",
        "print(geo_full[['theta_deg', 'phi_deg', 'coherence_theta', 'coherence_phi']].tail(10))\n",
        "\n",
        "print(\"\\nâœ… VCF geometry engine COMPLETE.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86B8zyBmPWlH",
        "outputId": "e05e543b-f947-4f5c-baad-08343e17a311"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§® Running VCF geometry engine with MONTHLY panel...\n",
            "âœ” Panel: 1355 rows, 9 metrics\n",
            "  Macro: ['GDP_US', 'CPI_US', 'PPI_US', 'UNRATE_US']\n",
            "  Liquidity: ['M2_US', 'DGS10_US', 'T10Y2Y_US']\n",
            "  Risk: ['VIX_US']\n",
            "  Equity: ['SPY_US']\n",
            "\n",
            "âœ” Full geometry rows: 394\n",
            "\n",
            "ğŸ“œ Full geometry saved: /content/drive/MyDrive/VCF-RESEARCH/geometry/vcf_geometry_full.csv\n",
            "   Date range: 1993-02-28 00:00:00 to 2025-11-30 00:00:00\n",
            "\n",
            "ğŸ“Š Latest 10 observations:\n",
            "\n",
            "            theta_deg    phi_deg  coherence_theta  coherence_phi\n",
            "date                                                            \n",
            "2025-02-28  17.639449  90.000672         0.105527       2.855327\n",
            "2025-03-31 -30.801143  82.461619         0.140370       2.657337\n",
            "2025-04-30 -29.110937  75.621664         0.129087       2.686039\n",
            "2025-05-31  -5.920853  92.816722         0.332492       2.838622\n",
            "2025-06-30  23.345190  97.159066         0.534784       3.061802\n",
            "2025-07-31  28.826804  96.966658         0.860344       3.156777\n",
            "2025-08-31  37.133119  99.895599         0.796984       3.269186\n",
            "2025-09-30  32.274877  97.441206         0.930397       3.403475\n",
            "2025-10-31  55.602752  94.731274         1.444480       3.493628\n",
            "2025-11-30  56.272286  80.391234         1.433112       3.381180\n",
            "\n",
            "âœ… VCF geometry engine COMPLETE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "full_path = os.path.join(BASE_DIR, \"geometry\", \"vcf_geometry_full.csv\")\n",
        "\n",
        "geo = pd.read_csv(full_path, parse_dates=['date'], index_col='date')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“ˆ VCF MARKET STATE - November 2025\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "latest = geo.iloc[-1]\n",
        "print(f\"\\nDate: {geo.index[-1].strftime('%B %Y')}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Pillar Scores (z-scores):\")\n",
        "print(f\"  Macro:     {latest['macro_score']:>7.3f}\")\n",
        "print(f\"  Liquidity: {latest['liquidity_score']:>7.3f}\")\n",
        "print(f\"  Risk (VIX):{latest['risk_score']:>7.3f}\")\n",
        "print(f\"  Equity:    {latest['equity_score']:>7.3f}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Geometric Coordinates:\")\n",
        "print(f\"  Theta (Macro/Liquidity):  {latest['theta_deg']:>6.1f}Â°  (coherence: {latest['coherence_theta']:.2f})\")\n",
        "print(f\"  Phi (Equity/Risk):        {latest['phi_deg']:>6.1f}Â°  (coherence: {latest['coherence_phi']:.2f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ” INTERPRETATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Theta interpretation\n",
        "theta = latest['theta_deg']\n",
        "if 0 <= theta <= 90:\n",
        "    regime_theta = \"EXPANSION (positive macro, positive liquidity)\"\n",
        "elif -90 <= theta < 0:\n",
        "    regime_theta = \"SLOWDOWN (weak macro, strong liquidity)\"\n",
        "elif 90 < theta <= 180:\n",
        "    regime_theta = \"TIGHTENING (strong macro, weak liquidity)\"\n",
        "else:\n",
        "    regime_theta = \"CONTRACTION (weak macro, weak liquidity)\"\n",
        "\n",
        "print(f\"\\nÎ˜ = {theta:.1f}Â° â†’ {regime_theta}\")\n",
        "\n",
        "# Phi interpretation\n",
        "phi = latest['phi_deg']\n",
        "if 45 < phi <= 135:\n",
        "    regime_phi = \"RISK-ON (strong equities, low volatility)\"\n",
        "elif -45 < phi <= 45:\n",
        "    regime_phi = \"LOW VOL GRIND (subdued risk, neutral equities)\"\n",
        "elif 135 < phi or phi <= -135:\n",
        "    regime_phi = \"EUPHORIA/MELT-UP (high equities, high vol)\"\n",
        "else:\n",
        "    regime_phi = \"RISK-OFF (weak equities, high volatility)\"\n",
        "\n",
        "print(f\"Î¦ = {phi:.1f}Â° â†’ {regime_phi}\")\n",
        "\n",
        "# Coherence\n",
        "print(f\"\\nSignal Strength:\")\n",
        "if latest['coherence_theta'] > 1.5:\n",
        "    print(f\"  â€¢ Macro/Liquidity: STRONG (coherence {latest['coherence_theta']:.2f})\")\n",
        "elif latest['coherence_theta'] > 0.5:\n",
        "    print(f\"  â€¢ Macro/Liquidity: MODERATE (coherence {latest['coherence_theta']:.2f})\")\n",
        "else:\n",
        "    print(f\"  â€¢ Macro/Liquidity: WEAK (coherence {latest['coherence_theta']:.2f})\")\n",
        "\n",
        "if latest['coherence_phi'] > 2.0:\n",
        "    print(f\"  â€¢ Equity/Risk: VERY STRONG (coherence {latest['coherence_phi']:.2f})\")\n",
        "elif latest['coherence_phi'] > 1.0:\n",
        "    print(f\"  â€¢ Equity/Risk: STRONG (coherence {latest['coherence_phi']:.2f})\")\n",
        "else:\n",
        "    print(f\"  â€¢ Equity/Risk: MODERATE (coherence {latest['coherence_phi']:.2f})\")\n",
        "\n",
        "# Trend analysis\n",
        "print(\"\\nğŸ“ˆ Recent Trend (last 6 months):\")\n",
        "recent = geo.tail(6)\n",
        "theta_trend = \"rising\" if recent['theta_deg'].iloc[-1] > recent['theta_deg'].iloc[0] else \"falling\"\n",
        "phi_trend = \"rising\" if recent['phi_deg'].iloc[-1] > recent['phi_deg'].iloc[0] else \"falling\"\n",
        "print(f\"  â€¢ Theta: {theta_trend} ({recent['theta_deg'].iloc[0]:.1f}Â° â†’ {recent['theta_deg'].iloc[-1]:.1f}Â°)\")\n",
        "print(f\"  â€¢ Phi: {phi_trend} ({recent['phi_deg'].iloc[0]:.1f}Â° â†’ {recent['phi_deg'].iloc[-1]:.1f}Â°)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhPh0o_ZPrXj",
        "outputId": "661e809c-db76-4d21-ff44-4b2b9f55aa8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ğŸ“ˆ VCF MARKET STATE - November 2025\n",
            "======================================================================\n",
            "\n",
            "Date: November 2025\n",
            "\n",
            "ğŸ“Š Pillar Scores (z-scores):\n",
            "  Macro:       1.294\n",
            "  Liquidity:   0.654\n",
            "  Risk (VIX):  0.593\n",
            "  Equity:      3.330\n",
            "\n",
            "ğŸ¯ Geometric Coordinates:\n",
            "  Theta (Macro/Liquidity):    56.3Â°  (coherence: 1.43)\n",
            "  Phi (Equity/Risk):          80.4Â°  (coherence: 3.38)\n",
            "\n",
            "======================================================================\n",
            "ğŸ” INTERPRETATION\n",
            "======================================================================\n",
            "\n",
            "Î˜ = 56.3Â° â†’ EXPANSION (positive macro, positive liquidity)\n",
            "Î¦ = 80.4Â° â†’ RISK-ON (strong equities, low volatility)\n",
            "\n",
            "Signal Strength:\n",
            "  â€¢ Macro/Liquidity: MODERATE (coherence 1.43)\n",
            "  â€¢ Equity/Risk: VERY STRONG (coherence 3.38)\n",
            "\n",
            "ğŸ“ˆ Recent Trend (last 6 months):\n",
            "  â€¢ Theta: rising (23.3Â° â†’ 56.3Â°)\n",
            "  â€¢ Phi: falling (97.2Â° â†’ 80.4Â°)\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "geo_path = os.path.join(BASE_DIR, \"geometry\", \"vcf_geometry_full.csv\")\n",
        "output_dir = os.path.join(BASE_DIR, \"visuals\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load data\n",
        "geo = pd.read_csv(geo_path, parse_dates=['date'], index_col='date')\n",
        "\n",
        "print(\"ğŸ¨ Creating VCF visualization suite...\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# FIGURE 1: Full Time Series Dashboard\n",
        "# ==============================================================================\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "gs = GridSpec(4, 2, figure=fig, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Theta over time\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "ax1.plot(geo.index, geo['theta_deg'], linewidth=1.5, color='steelblue')\n",
        "ax1.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
        "ax1.axhline(45, color='orange', linestyle='--', alpha=0.3, label='45Â° (balanced)')\n",
        "ax1.axhline(-45, color='orange', linestyle='--', alpha=0.3)\n",
        "ax1.fill_between(geo.index, 0, 90, alpha=0.1, color='green', label='Expansion')\n",
        "ax1.fill_between(geo.index, -90, 0, alpha=0.1, color='red', label='Slowdown')\n",
        "ax1.set_ylabel('Theta (degrees)', fontsize=11)\n",
        "ax1.set_title('VCF Theta: Macro-Liquidity Plane', fontsize=13, fontweight='bold')\n",
        "ax1.legend(loc='upper left', fontsize=9)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. Phi over time\n",
        "ax2 = fig.add_subplot(gs[1, :])\n",
        "ax2.plot(geo.index, geo['phi_deg'], linewidth=1.5, color='darkgreen')\n",
        "ax2.axhline(90, color='green', linestyle='--', alpha=0.5, label='90Â° (pure risk-on)')\n",
        "ax2.axhline(0, color='red', linestyle='--', alpha=0.5, label='0Â° (risk-off)')\n",
        "ax2.fill_between(geo.index, 45, 135, alpha=0.1, color='green', label='Risk-On Zone')\n",
        "ax2.fill_between(geo.index, -135, -45, alpha=0.1, color='red', label='Risk-Off Zone')\n",
        "ax2.set_ylabel('Phi (degrees)', fontsize=11)\n",
        "ax2.set_title('VCF Phi: Equity-Risk Plane', fontsize=13, fontweight='bold')\n",
        "ax2.legend(loc='upper left', fontsize=9)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# 3. Coherence Theta\n",
        "ax3 = fig.add_subplot(gs[2, 0])\n",
        "ax3.plot(geo.index, geo['coherence_theta'], linewidth=1.5, color='purple')\n",
        "ax3.axhline(1.0, color='orange', linestyle='--', alpha=0.5, label='Threshold')\n",
        "ax3.fill_between(geo.index, 0, geo['coherence_theta'], alpha=0.2, color='purple')\n",
        "ax3.set_ylabel('Coherence', fontsize=11)\n",
        "ax3.set_title('Theta Coherence (Signal Strength)', fontsize=12, fontweight='bold')\n",
        "ax3.legend(fontsize=9)\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Coherence Phi\n",
        "ax4 = fig.add_subplot(gs[2, 1])\n",
        "ax4.plot(geo.index, geo['coherence_phi'], linewidth=1.5, color='darkred')\n",
        "ax4.axhline(2.0, color='orange', linestyle='--', alpha=0.5, label='Strong threshold')\n",
        "ax4.fill_between(geo.index, 0, geo['coherence_phi'], alpha=0.2, color='darkred')\n",
        "ax4.set_ylabel('Coherence', fontsize=11)\n",
        "ax4.set_title('Phi Coherence (Signal Strength)', fontsize=12, fontweight='bold')\n",
        "ax4.legend(fontsize=9)\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "# 5. Pillar scores\n",
        "ax5 = fig.add_subplot(gs[3, :])\n",
        "ax5.plot(geo.index, geo['macro_score'], label='Macro', linewidth=1.2, alpha=0.8)\n",
        "ax5.plot(geo.index, geo['liquidity_score'], label='Liquidity', linewidth=1.2, alpha=0.8)\n",
        "ax5.plot(geo.index, geo['risk_score'], label='Risk (VIX)', linewidth=1.2, alpha=0.8)\n",
        "ax5.plot(geo.index, geo['equity_score'], label='Equity (SPY)', linewidth=1.2, alpha=0.8)\n",
        "ax5.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
        "ax5.set_ylabel('Z-Score', fontsize=11)\n",
        "ax5.set_xlabel('Date', fontsize=11)\n",
        "ax5.set_title('Four Pillar Scores (Z-Scores)', fontsize=12, fontweight='bold')\n",
        "ax5.legend(loc='upper left', fontsize=9, ncol=4)\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "fig.suptitle('Vector Cycle Framework: Complete Geometric Analysis',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "dashboard_path = os.path.join(output_dir, \"vcf_dashboard_full.png\")\n",
        "plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Saved: {dashboard_path}\")\n",
        "plt.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# FIGURE 2: Polar Plot - Current State\n",
        "# ==============================================================================\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# Theta polar plot (last 5 years)\n",
        "recent = geo.last('5Y')\n",
        "theta_rad = np.radians(recent['theta_deg'])\n",
        "colors_theta = plt.cm.RdYlGn((recent['coherence_theta'] - recent['coherence_theta'].min()) /\n",
        "                              (recent['coherence_theta'].max() - recent['coherence_theta'].min()))\n",
        "\n",
        "scatter1 = ax1.scatter(theta_rad, recent['coherence_theta'],\n",
        "                       c=recent.index.map(mdates.date2num),\n",
        "                       s=50, alpha=0.6, cmap='viridis')\n",
        "ax1.plot(theta_rad, recent['coherence_theta'], alpha=0.3, color='gray')\n",
        "ax1.set_theta_zero_location('E')\n",
        "ax1.set_theta_direction(1)\n",
        "ax1.set_title('Theta: Macro-Liquidity Plane\\n(Last 5 Years)',\n",
        "              fontsize=13, fontweight='bold', pad=20)\n",
        "ax1.set_ylim(0, recent['coherence_theta'].max() * 1.1)\n",
        "\n",
        "# Add regime labels\n",
        "ax1.text(np.radians(45), ax1.get_ylim()[1]*0.9, 'Expansion',\n",
        "         ha='center', fontsize=10, color='green', fontweight='bold')\n",
        "ax1.text(np.radians(-45), ax1.get_ylim()[1]*0.9, 'Slowdown',\n",
        "         ha='center', fontsize=10, color='red', fontweight='bold')\n",
        "\n",
        "# Phi polar plot\n",
        "phi_rad = np.radians(recent['phi_deg'])\n",
        "scatter2 = ax2.scatter(phi_rad, recent['coherence_phi'],\n",
        "                       c=recent.index.map(mdates.date2num),\n",
        "                       s=50, alpha=0.6, cmap='viridis')\n",
        "ax2.plot(phi_rad, recent['coherence_phi'], alpha=0.3, color='gray')\n",
        "ax2.set_theta_zero_location('E')\n",
        "ax2.set_theta_direction(1)\n",
        "ax2.set_title('Phi: Equity-Risk Plane\\n(Last 5 Years)',\n",
        "              fontsize=13, fontweight='bold', pad=20)\n",
        "ax2.set_ylim(0, recent['coherence_phi'].max() * 1.1)\n",
        "\n",
        "# Add regime labels\n",
        "ax2.text(np.radians(90), ax2.get_ylim()[1]*0.9, 'Risk-On',\n",
        "         ha='center', fontsize=10, color='green', fontweight='bold')\n",
        "ax2.text(np.radians(-90), ax2.get_ylim()[1]*0.9, 'Risk-Off',\n",
        "         ha='center', fontsize=10, color='red', fontweight='bold')\n",
        "\n",
        "# Colorbar\n",
        "cbar = plt.colorbar(scatter2, ax=[ax1, ax2], orientation='horizontal',\n",
        "                    pad=0.1, aspect=40)\n",
        "cbar.set_label('Time (darker = more recent)', fontsize=10)\n",
        "\n",
        "fig.suptitle('VCF Geometric State Space', fontsize=16, fontweight='bold')\n",
        "\n",
        "polar_path = os.path.join(output_dir, \"vcf_polar_recent.png\")\n",
        "plt.savefig(polar_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Saved: {polar_path}\")\n",
        "plt.close()\n",
        "\n",
        "# ==============================================================================\n",
        "# FIGURE 3: Recent Conditions (Last 2 Years)\n",
        "# ==============================================================================\n",
        "recent_2y = geo.last('2Y')\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Theta with regime shading\n",
        "axes[0].plot(recent_2y.index, recent_2y['theta_deg'], linewidth=2, color='steelblue')\n",
        "axes[0].axhline(0, color='black', linestyle='-', alpha=0.3)\n",
        "axes[0].axhline(45, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].axhline(-45, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].fill_between(recent_2y.index, 0, 90, alpha=0.1, color='green')\n",
        "axes[0].fill_between(recent_2y.index, -90, 0, alpha=0.1, color='red')\n",
        "axes[0].set_ylabel('Theta (Â°)', fontsize=12)\n",
        "axes[0].set_title('Macro-Liquidity Dynamics (Last 2 Years)', fontsize=13, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Phi with regime shading\n",
        "axes[1].plot(recent_2y.index, recent_2y['phi_deg'], linewidth=2, color='darkgreen')\n",
        "axes[1].axhline(90, color='green', linestyle='--', alpha=0.5)\n",
        "axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1].fill_between(recent_2y.index, 45, 135, alpha=0.1, color='green')\n",
        "axes[1].fill_between(recent_2y.index, -135, -45, alpha=0.1, color='red')\n",
        "axes[1].set_ylabel('Phi (Â°)', fontsize=12)\n",
        "axes[1].set_title('Equity-Risk Dynamics (Last 2 Years)', fontsize=13, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Both coherences\n",
        "axes[2].plot(recent_2y.index, recent_2y['coherence_theta'],\n",
        "             label='Theta Coherence', linewidth=2, color='purple')\n",
        "axes[2].plot(recent_2y.index, recent_2y['coherence_phi'],\n",
        "             label='Phi Coherence', linewidth=2, color='darkred')\n",
        "axes[2].axhline(1.0, color='orange', linestyle='--', alpha=0.5, label='Moderate threshold')\n",
        "axes[2].axhline(2.0, color='red', linestyle='--', alpha=0.5, label='Strong threshold')\n",
        "axes[2].set_ylabel('Coherence', fontsize=12)\n",
        "axes[2].set_xlabel('Date', fontsize=12)\n",
        "axes[2].set_title('Signal Strength (Last 2 Years)', fontsize=13, fontweight='bold')\n",
        "axes[2].legend(fontsize=10)\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "recent_path = os.path.join(output_dir, \"vcf_recent_2years.png\")\n",
        "plt.savefig(recent_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Saved: {recent_path}\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\nâœ… All visualizations saved to: {output_dir}\")\n",
        "print(f\"\\nğŸ“Š Generated 3 charts:\")\n",
        "print(f\"   1. vcf_dashboard_full.png - Complete time series\")\n",
        "print(f\"   2. vcf_polar_recent.png - Polar state space\")\n",
        "print(f\"   3. vcf_recent_2years.png - Recent dynamics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vF6AxS4QbVs",
        "outputId": "ef2ee076-b9b0-468b-bb29-4921daad1b46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¨ Creating VCF visualization suite...\n",
            "\n",
            "âœ… Saved: /content/drive/MyDrive/VCF-RESEARCH/visuals/vcf_dashboard_full.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3980329104.py:96: FutureWarning: last is deprecated and will be removed in a future version. Please create a mask and filter using `.loc` instead\n",
            "  recent = geo.last('5Y')\n",
            "/tmp/ipython-input-3980329104.py:96: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
            "  recent = geo.last('5Y')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: /content/drive/MyDrive/VCF-RESEARCH/visuals/vcf_polar_recent.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3980329104.py:150: FutureWarning: last is deprecated and will be removed in a future version. Please create a mask and filter using `.loc` instead\n",
            "  recent_2y = geo.last('2Y')\n",
            "/tmp/ipython-input-3980329104.py:150: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
            "  recent_2y = geo.last('2Y')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: /content/drive/MyDrive/VCF-RESEARCH/visuals/vcf_recent_2years.png\n",
            "\n",
            "âœ… All visualizations saved to: /content/drive/MyDrive/VCF-RESEARCH/visuals\n",
            "\n",
            "ğŸ“Š Generated 3 charts:\n",
            "   1. vcf_dashboard_full.png - Complete time series\n",
            "   2. vcf_polar_recent.png - Polar state space\n",
            "   3. vcf_recent_2years.png - Recent dynamics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "summary_path = os.path.join(BASE_DIR, \"VCF_PHASE3_SUMMARY.md\")\n",
        "\n",
        "summary = f\"\"\"# VCF Phase III - Pilot Run Summary\n",
        "\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## âœ… Phase III Completion Status\n",
        "\n",
        "### Data Pipeline\n",
        "- âœ… Normalized panel created with 9 metrics\n",
        "- âœ… Monthly resampling implemented (1,355 rows)\n",
        "- âœ… Registry updated with proper category assignments\n",
        "- âœ… Date alignment issues resolved\n",
        "\n",
        "### Metrics Included\n",
        "**Macro (4):** GDP_US, CPI_US, PPI_US, UNRATE_US\n",
        "**Liquidity (3):** M2_US, DGS10_US, T10Y2Y_US\n",
        "**Risk (1):** VIX_US\n",
        "**Equity (1):** SPY_US\n",
        "\n",
        "### Geometry Engine\n",
        "- âœ… 4-pillar scores computed (macro, liquidity, risk, equity)\n",
        "- âœ… Theta angle (macro/liquidity plane): **working**\n",
        "- âœ… Phi angle (equity/risk plane): **working**\n",
        "- âœ… Coherence metrics: **working**\n",
        "- âœ… Output: 394 monthly observations (Feb 1993 - Nov 2025)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Current Market State (November 2025)\n",
        "\n",
        "### Geometric Coordinates\n",
        "- **Theta:** 56.3Â° (Expansion regime)\n",
        "- **Phi:** 80.4Â° (Risk-on regime)\n",
        "- **Coherence Theta:** 1.43 (Moderate signal)\n",
        "- **Coherence Phi:** 3.38 (Very strong signal)\n",
        "\n",
        "### Pillar Scores (Z-scores)\n",
        "- **Macro:** +1.29Ïƒ (above average)\n",
        "- **Liquidity:** +0.65Ïƒ (above average)\n",
        "- **Risk (VIX):** +0.59Ïƒ (slightly elevated)\n",
        "- **Equity (SPY):** +3.33Ïƒ (extreme)\n",
        "\n",
        "### Interpretation\n",
        "**Regime:** EXPANSION + RISK-ON\n",
        "- Both macro and liquidity conditions are positive (theta = 56Â°)\n",
        "- Equities extremely elevated with moderate volatility (phi = 80Â°)\n",
        "- Theta rising over past 6 months (23Â° â†’ 56Â°) indicating strengthening fundamentals\n",
        "- Equity signal very strong (coherence 3.38) but at extreme levels (3.3Ïƒ)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Key Files\n",
        "\n",
        "### Data\n",
        "- `data_clean/normalized_panel_monthly.csv` - Monthly panel (9 metrics, 1,355 rows)\n",
        "- `registry/vcf_metric_registry.json` - Metric definitions\n",
        "\n",
        "### Outputs\n",
        "- `geometry/vcf_geometry_full.csv` - Full 4-pillar geometry (394 months)\n",
        "- `visuals/vcf_dashboard_full.png` - Complete time series dashboard\n",
        "- `visuals/vcf_polar_recent.png` - Polar state space (last 5 years)\n",
        "- `visuals/vcf_recent_2years.png` - Recent dynamics\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ Working Code Blocks\n",
        "\n",
        "### 1. Mount Drive and Set Paths\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "```\n",
        "\n",
        "### 2. Build Monthly Panel (if needed)\n",
        "```python\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "panel_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel.csv\")\n",
        "output_path = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel_monthly.csv\")\n",
        "\n",
        "panel = pd.read_csv(panel_path, parse_dates=['date'])\n",
        "panel = panel.set_index('date').sort_index()\n",
        "panel_monthly = panel.resample('ME').last()\n",
        "panel_monthly = panel_monthly.ffill(limit=5)\n",
        "panel_monthly.to_csv(output_path)\n",
        "print(f\"âœ… Monthly panel: {{panel_monthly.shape[0]}} rows\")\n",
        "```\n",
        "\n",
        "### 3. Run Geometry Engine\n",
        "```python\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/VCF-RESEARCH\"\n",
        "REGISTRY_PATH = os.path.join(BASE_DIR, \"registry\", \"vcf_metric_registry.json\")\n",
        "PANEL_PATH = os.path.join(BASE_DIR, \"data_clean\", \"normalized_panel_monthly.csv\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"geometry\")\n",
        "\n",
        "# Load data\n",
        "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
        "panel = panel.set_index(\"date\").sort_index()\n",
        "\n",
        "with open(REGISTRY_PATH, \"r\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "# Group metrics\n",
        "def metric_ids_for(categories):\n",
        "    return [\n",
        "        metric_id\n",
        "        for metric_id, info in registry.items()\n",
        "        if info.get(\"category\") in categories and metric_id in panel.columns\n",
        "    ]\n",
        "\n",
        "macro_metrics = metric_ids_for({{\"Macro\", \"Labor\"}})\n",
        "liquidity_metrics = metric_ids_for({{\"Liquidity\"}})\n",
        "risk_metrics = metric_ids_for({{\"Volatility\"}})\n",
        "equity_metrics = metric_ids_for({{\"Equities\"}})\n",
        "\n",
        "# Build pillar scores\n",
        "scores = pd.DataFrame(index=panel.index)\n",
        "scores[\"macro_score\"] = panel[macro_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"liquidity_score\"] = panel[liquidity_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"risk_score\"] = panel[risk_metrics].mean(axis=1, skipna=True)\n",
        "scores[\"equity_score\"] = panel[equity_metrics].mean(axis=1, skipna=True)\n",
        "\n",
        "def zscore(series):\n",
        "    s = series.dropna()\n",
        "    if s.empty or s.std(ddof=0) == 0:\n",
        "        return series * np.nan\n",
        "    return (series - s.mean()) / s.std(ddof=0)\n",
        "\n",
        "# Full geometry\n",
        "mask_full = (scores[\"macro_score\"].notna() & scores[\"liquidity_score\"].notna() &\n",
        "             scores[\"risk_score\"].notna() & scores[\"equity_score\"].notna())\n",
        "\n",
        "macro_z = zscore(scores.loc[mask_full, \"macro_score\"])\n",
        "liq_z = zscore(scores.loc[mask_full, \"liquidity_score\"])\n",
        "risk_z = zscore(scores.loc[mask_full, \"risk_score\"])\n",
        "equity_z = zscore(scores.loc[mask_full, \"equity_score\"])\n",
        "\n",
        "theta = np.degrees(np.arctan2(macro_z, liq_z))\n",
        "phi = np.degrees(np.arctan2(equity_z, risk_z))\n",
        "coherence_theta = np.sqrt(macro_z**2 + liq_z**2)\n",
        "coherence_phi = np.sqrt(equity_z**2 + risk_z**2)\n",
        "\n",
        "geo_full = pd.DataFrame({{\n",
        "    \"macro_score\": scores.loc[mask_full, \"macro_score\"],\n",
        "    \"liquidity_score\": scores.loc[mask_full, \"liquidity_score\"],\n",
        "    \"risk_score\": scores.loc[mask_full, \"risk_score\"],\n",
        "    \"equity_score\": scores.loc[mask_full, \"equity_score\"],\n",
        "    \"theta_deg\": theta,\n",
        "    \"phi_deg\": phi,\n",
        "    \"coherence_theta\": coherence_theta,\n",
        "    \"coherence_phi\": coherence_phi,\n",
        "}}, index=scores.index[mask_full])\n",
        "\n",
        "full_path = os.path.join(OUT_DIR, \"vcf_geometry_full.csv\")\n",
        "geo_full.to_csv(full_path, index_label=\"date\")\n",
        "print(f\"âœ… Geometry saved: {{geo_full.shape[0]}} rows\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Next Steps\n",
        "\n",
        "### Immediate (Phase III Expansion)\n",
        "1. Add more metrics to each pillar:\n",
        "   - Macro: ISM, housing starts, capacity utilization\n",
        "   - Liquidity: Fed balance sheet, credit spreads\n",
        "   - Risk: MOVE index, credit vol\n",
        "   - Equity: Sector breadth, earnings yields\n",
        "\n",
        "2. Test alternative pillar definitions:\n",
        "   - Should rates be split differently?\n",
        "   - Credit metrics: macro or liquidity?\n",
        "\n",
        "### Phase IV Planning\n",
        "1. Regime detection and labeling\n",
        "2. Historical regime analysis (1987 crash, 2008 GFC, COVID, etc.)\n",
        "3. KAM theory implementation for multi-frequency coupling\n",
        "4. Backtest framework for validation\n",
        "\n",
        "### Long-term\n",
        "1. Expand to international markets\n",
        "2. Add commodities and currencies\n",
        "3. Build global model\n",
        "4. Academic paper preparation\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Technical Notes\n",
        "\n",
        "### Key Fixes Applied\n",
        "1. **Path correction:** VCF-RESEARCH (with hyphen) in MyDrive\n",
        "2. **Category separation:** Moved rates from dual assignment to Liquidity only\n",
        "3. **Monthly resampling:** Resolved daily/monthly data misalignment\n",
        "4. **Panel creation:** Built from individual normalized CSVs\n",
        "\n",
        "### Lessons Learned\n",
        "- Always use monthly frequency for macro data alignment\n",
        "- Avoid dual category assignments (causes identical pillar scores)\n",
        "- Forward-fill rates data to month-end for consistency\n",
        "- Check date alignment before computing geometry\n",
        "\n",
        "---\n",
        "\n",
        "**Phase III Status: COMPLETE âœ…**\n",
        "\n",
        "*VCF pilot successfully processes 4 inputs with proper geometric state space representation.*\n",
        "\"\"\"\n",
        "\n",
        "with open(summary_path, 'w') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "print(f\"âœ… Phase III summary saved to:\")\n",
        "print(f\"   {summary_path}\")\n",
        "print(f\"\\nğŸ“‹ Summary includes:\")\n",
        "print(\"   â€¢ Current market state interpretation\")\n",
        "print(\"   â€¢ All working code blocks\")\n",
        "print(\"   â€¢ File locations\")\n",
        "print(\"   â€¢ Next steps roadmap\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "222ZYjfBQxqT",
        "outputId": "9558cf16-0a6b-469d-86ec-01e34cc513b6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Phase III summary saved to:\n",
            "   /content/drive/MyDrive/VCF-RESEARCH/VCF_PHASE3_SUMMARY.md\n",
            "\n",
            "ğŸ“‹ Summary includes:\n",
            "   â€¢ Current market state interpretation\n",
            "   â€¢ All working code blocks\n",
            "   â€¢ File locations\n",
            "   â€¢ Next steps roadmap\n"
          ]
        }
      ]
    }
  ]
}